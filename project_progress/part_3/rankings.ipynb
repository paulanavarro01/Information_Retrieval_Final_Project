{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85085dc1",
   "metadata": {},
   "source": [
    "RANKINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96463d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Upload the data and import the libraries:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # go up from part_3\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from part_2.indexing_evaluation import load_processed_docs, create_index_tfidf, search_tf_idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0660c7a5",
   "metadata": {},
   "source": [
    "- TF-IDF + Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd214cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was already implemented in part2:\n",
    "\n",
    "def ranking_docs(terms,docs,index,idf,tf,title_index):\n",
    "    \"\"\"\n",
    "    Compute a ranking score for each document using the TF-IDF \n",
    "    cosine similarity between the query and document vectors\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #create a map form pid to tf list index\n",
    "    pid_idx={}\n",
    "    for term in terms:\n",
    "        if term in index:\n",
    "            for i, (pid,posting) in enumerate(index[term]):\n",
    "                pid_idx.setdefault(pid,{})[term]=i\n",
    "                \n",
    "    #initialize query and documnent vectors\n",
    "    vectors_doc=defaultdict(lambda: [0]*len(terms))\n",
    "    query_vector= [0]*len(terms)\n",
    "    \n",
    "    #compute query term frequencies\n",
    "    query_counts=collections.Counter(terms)\n",
    "    query_norm= np.linalg.norm(list(query_counts.values()))\n",
    "\n",
    "    #build query vector and compute document vectors\n",
    "    for i,term in enumerate(terms):\n",
    "        if term not in index:\n",
    "            continue\n",
    "        \n",
    "        #compute query TF-IDF\n",
    "        query_tf=query_counts[term]/query_norm if query_norm>0 else 0\n",
    "        query_vector[i]=query_tf*idf.get(term,0.0)\n",
    "\n",
    "        # compute document TF-IDF for each doc containing the term\n",
    "        for pid in docs:\n",
    "            map_term= pid_idx.get(pid,{})\n",
    "            if term in map_term:\n",
    "                vectors_doc[pid][i]=tf[term].get(pid,0.0)*idf.get(term,0.0)\n",
    "\n",
    "    #compute cosine similarity between query and document vectors\n",
    "    scores=[[np.dot(v,query_vector),doc] for doc, v in vectors_doc.items()]\n",
    "    scores.sort(reverse=True)\n",
    "    return [s[1] for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9970d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index, tf, idf, title_index):\n",
    "    \"\"\"\n",
    "    Executes a search query usinf AND logic. \n",
    "    Only documents containing all query terms are considered.\n",
    "    Results are ranqued by TF-IDF cosine similarity.\n",
    "    \n",
    "    \"\"\"\n",
    "    query_terms=build_terms(query)\n",
    "    if not query_terms:\n",
    "        return []\n",
    "\n",
    "    #start with first query term\n",
    "    if query_terms[0] not in index: \n",
    "        return []\n",
    "\n",
    "    \n",
    "    docs_set= set(posting[0]for posting in index[query_terms[0]])\n",
    "\n",
    "    #only keeping documents that are present in all term's postings\n",
    "    for term in query_terms[1:]:\n",
    "        if term in index:\n",
    "            term_docs= [posting[0] for posting in index[term]]\n",
    "            docs_set &= set(term_docs)\n",
    "        else:\n",
    "            docs_set=set()\n",
    "            break\n",
    "    \n",
    "    if not docs_set:\n",
    "        return []\n",
    "    \n",
    "    #rank final set of documents\n",
    "    docs=list(docs_set)\n",
    "   \n",
    "    return ranking_docs(query_terms,docs,index,idf,tf,title_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2302062",
   "metadata": {},
   "source": [
    "- BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17934222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(terms,docs,index,df,title_index, k=1.5, b=0.75):\n",
    "    \n",
    "    N = len(title_index) #total num of documents\n",
    "    \n",
    "    #average length accross documents\n",
    "    doc_lenght= {}\n",
    "    for term, postings in index.items():\n",
    "        for pid, count in postings:\n",
    "            doc_length[pid]= doc_length.get(pid,0)+count\n",
    "            \n",
    "    avg_dl= sum(doc_lenght.values())/ len(doc_length) if doc_length else 0\n",
    "    \n",
    "    \n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    #Precompute IDF\n",
    "    for term in terms:\n",
    "        df_term = df.get(term, 0)\n",
    "        idf = math.log((N + 0.5)/(df_term + 0.5))\n",
    "        postings= dict(index.get(term, []))\n",
    "        \n",
    "        for pid in docs:\n",
    "            tf_idf= postings.get(pid,0)\n",
    "            ld = docs_length. get(pid, avg_dl)\n",
    "            denominator = tf_idf +k1*((1-b)+b*(ld/avg_dl))\n",
    "            score = idf* ((tf_idf*(k1+1))/denominator)\n",
    "            scores[pid]+= score\n",
    "    ranked_docs= sorted(scores.items(), key=lambda x:X[1], reverse= True)\n",
    "    return [doc for doc, _ in ranked_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3fd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bm25(query, index, df, title_index, k=1.5, b= 0.75):\n",
    "    \"\"\"\n",
    "    Executes a search query using AND logic. \n",
    "    Only documents containing all query terms are considered.\n",
    "    Results are ranqued by TF-IDF cosine similarity.\n",
    "    \n",
    "    \"\"\"\n",
    "    query_terms=build_terms(query)\n",
    "    if not query_terms:\n",
    "        return []\n",
    "\n",
    "    #start with first query term\n",
    "    if query_terms[0] not in index: \n",
    "        return []\n",
    "\n",
    "    \n",
    "    docs_set= set(posting[0]for posting in index[query_terms[0]])\n",
    "\n",
    "    #only keeping documents that are present in all term's postings\n",
    "    for term in query_terms[1:]:\n",
    "        if term in index:\n",
    "            term_docs= [posting[0] for posting in index[term]]\n",
    "            docs_set &= set(term_docs)\n",
    "        else:\n",
    "            docs_set=set()\n",
    "            break\n",
    "    \n",
    "    if not docs_set:\n",
    "        return []\n",
    "    \n",
    "    #rank final set of documents\n",
    "    docs=list(docs_set)\n",
    "   \n",
    "    return BM25(query_terms,docs,index,df,title_index, k=1.5, b=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771e9cb",
   "metadata": {},
   "source": [
    "- Our Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a84411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf42b1de",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "313a5d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed_docs.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#load preprocessed docs\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     docs\u001b[38;5;241m=\u001b[39m\u001b[43mload_processed_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#build inverted index and compute TF-IDF values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     index,tf,df,idf,title_index\u001b[38;5;241m=\u001b[39mcreate_index_tfidf(docs)\n",
      "File \u001b[1;32mc:\\Users\\paula\\Documents\\4th Year\\irwa-search-engine\\project_progress\\part_2\\indexing_evaluation.py:31\u001b[0m, in \u001b[0;36mload_processed_docs\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_processed_docs\u001b[39m(path\u001b[38;5;241m=\u001b[39mproc_doc_path):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Loads the processed product documents stored in JSONL format.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Each line is one JSON line representing one product.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     32\u001b[0m         docs\u001b[38;5;241m=\u001b[39m[json\u001b[38;5;241m.\u001b[39mloads(line)\u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed_docs.jsonl'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #load preprocessed docs\n",
    "    docs=load_processed_docs()\n",
    "    \n",
    "    #build inverted index and compute TF-IDF values\n",
    "    index,tf,df,idf,title_index=create_index_tfidf(docs)\n",
    "\n",
    "    \n",
    "    #test queries\n",
    "    queries=[\n",
    "        \"full sleeve black shirt\",\n",
    "        \"solid women white polo\",\n",
    "        \"print of multicolor neck grey shirt\",\n",
    "        \"slim fit men blue jeans\",\n",
    "        \"round collar full sleeves t-shirt\" \n",
    "    ]\n",
    "    \n",
    "    #run and display top results for each query\n",
    "    for q in queries:\n",
    "        result=search_tf_idf(q,index,tf,idf,title_index)\n",
    "        if not result:\n",
    "            print(\"No matching documents.\")\n",
    "        else:\n",
    "            print(f\"Top results for query: '{q}'\")\n",
    "            for pid in result[:10]:\n",
    "                print(f\"{pid}: {title_index.get(pid,'[No title]')}\")\n",
    "        result_bm25=search_bm25(q,index,df,title_index)\n",
    "        if not result_bm25:\n",
    "            print(\"No matching documents.\")\n",
    "        else:\n",
    "            print(f\"Top results for query: '{q}'\")\n",
    "            for pid in result_bm25[:10]:\n",
    "                print(f\"{pid}: {title_index.get(pid,'[No title]')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c6b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irwa_venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
